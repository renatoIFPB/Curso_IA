{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvmQ8QyJpZp3YHKNgMw1I2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/renatoIFPB/Curso_IA/blob/main/projeto_final_regressao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_Z7vHwZkrux7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from seaborn import load_dataset\n",
        "from sklearn import preprocessing, metrics\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import make_column_transformer\n",
        "\n",
        "df = load_dataset('taxis') #Carrega o dataset na variavel df\n",
        "df = df.dropna(how='any',axis=0) #Deleta linhas com valor vazio\n",
        "df = df.drop(['pickup','dropoff'], axis=1) #Deleta as colunas 'pickup', 'dropoff'\n",
        "\n",
        "# column_headers = list(df.columns.values)\n",
        "# print(\"The Column Header :\", column_headers)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "payment_df = pd.DataFrame(df, columns=['payment'])\n",
        "df['payment'] = labelencoder.fit_transform(payment_df['payment'])\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "pickup_zone_df = pd.DataFrame(df, columns=['pickup_zone'])\n",
        "df['pickup_zone'] = labelencoder.fit_transform(pickup_zone_df['pickup_zone'])\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "dropoff_zone_df = pd.DataFrame(df, columns=['dropoff_zone'])\n",
        "df['dropoff_zone'] = labelencoder.fit_transform(dropoff_zone_df['dropoff_zone'])\n",
        "\n",
        "column_transformer = make_column_transformer((OneHotEncoder(), ['color', 'pickup_borough', 'dropoff_borough']), remainder='passthrough')\n",
        "df = column_transformer.fit_transform(df)\n",
        "columns_names = column_transformer.get_feature_names_out()\n",
        "df = pd.DataFrame(data=df, columns=columns_names)"
      ],
      "metadata": {
        "id": "JLagIJ7jsHOo"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['remainder__payment'] # extrai a primeira coluna, que é o label para a variavel y\n",
        "X = df.drop(['remainder__payment'], axis=1) #deleta a coluna payment e copia o df para a variavel x\n",
        "\n",
        "df = X.values\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(df)\n",
        "X = pd.DataFrame(x_scaled)"
      ],
      "metadata": {
        "id": "chI1AFfmsL7t"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "count1=0\n",
        "count2=0\n",
        "for i in range(10): #Loop para executar a divisão dos dados de testes/treino e execução\n",
        "  train_data, test_data, train_labels, test_labels = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=None)\n",
        "\n",
        "  model1 = DecisionTreeRegressor()\n",
        "  model2 = DecisionTreeRegressor(criterion=\"poisson\", max_depth=2, min_samples_split=20)\n",
        "  model1.fit(train_data, train_labels)\n",
        "  model2.fit(train_data, train_labels)\n",
        "\n",
        "  result1 = model1.predict(test_data)\n",
        "  result2 = model2.predict(test_data)\n",
        "\n",
        "  count1+=float(mean_squared_error(test_labels, result1) * 100)\n",
        "  count2+=float(mean_squared_error(test_labels, result1) * 100)\n",
        "\n",
        "print('Media erro:',f'{count1 / 10:.3f}%') #Media das 10 execuções\n",
        "print('Media erro:',f'{count2 / 10:.3f}%') #Media das 10 execuções\n",
        "# print(mean_squared_error(test_labels, result1))\n",
        "# print(mean_squared_error(test_labels, result2))"
      ],
      "metadata": {
        "id": "n66a-YggsQs-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2254ec3-aa74-4c59-9fe2-75d87b4af505"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media erro: 7.589%\n",
            "Media erro: 7.589%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "count3=0\n",
        "count4=0\n",
        "for i in range(10): #Loop para executar a divisão dos dados de testes/treino e execução\n",
        "  train_data, test_data, train_labels, test_labels = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=None)\n",
        "\n",
        "  model3 = KNeighborsRegressor()\n",
        "  model4 = KNeighborsRegressor(n_neighbors=11, algorithm=\"brute\", weights=\"distance\")\n",
        "\n",
        "  model3.fit(train_data, train_labels)\n",
        "  model4.fit(train_data, train_labels)\n",
        "\n",
        "  result3 = model3.predict(test_data)\n",
        "  result4 = model4.predict(test_data)\n",
        "\n",
        "  count3+=float(mean_squared_error(test_labels, result3) * 100)\n",
        "  count4+=float(mean_squared_error(test_labels, result4) * 100)\n",
        "\n",
        "print('Media erro:',f'{count3 / 10:.3f}%') #Media das 10 execuções\n",
        "print('Media erro:',f'{count4 / 10:.3f}%') #Media das 10 execuções"
      ],
      "metadata": {
        "id": "GaVIznlwNC-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d070ad-0a0a-49bb-879f-782e3d551ff9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media erro: 9.142%\n",
            "Media erro: 8.444%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "count5=0\n",
        "count6=0\n",
        "for i in range(10): #Loop para executar a divisão dos dados de testes/treino e execução\n",
        "  train_data, test_data, train_labels, test_labels = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=None)\n",
        "\n",
        "  model5 = MLPRegressor()\n",
        "  model6 = MLPRegressor(hidden_layer_sizes=50, activation=\"identity\", solver=\"lbfgs\")\n",
        "\n",
        "  model5.fit(train_data, train_labels)\n",
        "  model6.fit(train_data, train_labels)\n",
        "\n",
        "  result5 = model5.predict(test_data)\n",
        "  result6 = model5.predict(test_data)\n",
        "\n",
        "  count5+=float(mean_squared_error(test_labels, result5) * 100)\n",
        "  count6+=float(mean_squared_error(test_labels, result6) * 100)\n",
        "\n",
        "print('Media erro:',f'{count5 / 10:.3f}%') #Media das 10 execuções\n",
        "print('Media erro:',f'{count6 / 10:.3f}%') #Media das 10 execuções"
      ],
      "metadata": {
        "id": "29dYukOOSdDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cae153c5-d923-4adf-c081-dbb3c1be734b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media erro: 4.534%\n",
            "Media erro: 4.534%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "count7=0\n",
        "count8=0\n",
        "for i in range(10): #Loop para executar a divisão dos dados de testes/treino e execução\n",
        "  train_data, test_data, train_labels, test_labels = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=None)\n",
        "\n",
        "  model7 = SVR()\n",
        "  model8 = SVR(kernel=\"linear\", C=0.5, gamma=\"auto\")\n",
        "\n",
        "  model7.fit(train_data, train_labels)\n",
        "  model8.fit(train_data, train_labels)\n",
        "\n",
        "  result7 = model7.predict(test_data)\n",
        "  result8 = model8.predict(test_data)\n",
        "\n",
        "  count7+=float(mean_squared_error(test_labels, result7) * 100)\n",
        "  count8+=float(mean_squared_error(test_labels, result8) * 100)\n",
        "\n",
        "print('Media erro:',f'{count7 / 10:.3f}%') #Media das 10 execuções\n",
        "print('Media erro:',f'{count8 / 10:.3f}%') #Media das 10 execuções"
      ],
      "metadata": {
        "id": "LWGqfbpVU7lV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ad797f3-6d67-46d9-8606-e10d6241f252"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media erro: 9.752%\n",
            "Media erro: 15.121%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "\n",
        "count9=0\n",
        "count10=0\n",
        "for i in range(10): #Loop para executar a divisão dos dados de testes/treino e execução\n",
        "  train_data, test_data, train_labels, test_labels = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=None)\n",
        "\n",
        "  model9 = RandomForestRegressor(criterion=\"absolute_error\", min_samples_split=5, min_samples_leaf=3)\n",
        "  model10 = GradientBoostingRegressor(loss=\"absolute_error\", learning_rate=0.3, criterion=\"squared_error\")\n",
        "\n",
        "  model9.fit(train_data, train_labels)\n",
        "  model10.fit(train_data, train_labels)\n",
        "\n",
        "  result9 = model9.predict(test_data)\n",
        "  result10 = model10.predict(test_data)\n",
        "\n",
        "  count9+=float(mean_squared_error(test_labels, result9) * 100)\n",
        "  count10+=float(mean_squared_error(test_labels, result10) * 100)\n",
        "\n",
        "print('Media erro:',f'{count9 / 10:.3f}%') #Media das 10 execuções\n",
        "print('Media erro:',f'{count10 / 10:.3f}%') #Media das 10 execuções"
      ],
      "metadata": {
        "id": "ICfNfjofW3Q1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e42a63c4-857d-4f7e-c43e-ff7090a3f6c4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media erro: 4.014%\n",
            "Media erro: 28.109%\n"
          ]
        }
      ]
    }
  ]
}