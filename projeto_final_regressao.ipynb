{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/QB+Dfb2VS17Ewba0Gvb4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/renatoIFPB/Curso_IA/blob/main/projeto_final_regressao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_Z7vHwZkrux7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from seaborn import load_dataset\n",
        "from sklearn import preprocessing, metrics\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import make_column_transformer\n",
        "\n",
        "df = load_dataset('taxis') #Carrega o dataset na variavel df\n",
        "df = df.dropna(how='any',axis=0) #Deleta linhas com valor vazio\n",
        "df = df.drop(['pickup', 'dropoff', 'pickup_zone', 'dropoff_zone'], axis=1) #Deleta as colunas 'pickup', 'dropoff', 'pickup_zone', 'dropoff_zone'\n",
        "\n",
        "# column_headers = list(df.columns.values)\n",
        "# print(\"The Column Header :\", column_headers)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "payment_df = pd.DataFrame(df, columns=['payment'])\n",
        "df['payment'] = labelencoder.fit_transform(payment_df['payment'])\n",
        "\n",
        "column_transformer = make_column_transformer((OneHotEncoder(), ['color', 'pickup_borough', 'dropoff_borough']), remainder='passthrough')\n",
        "df = column_transformer.fit_transform(df)\n",
        "columns_names = column_transformer.get_feature_names_out()\n",
        "df = pd.DataFrame(data=df, columns=columns_names)"
      ],
      "metadata": {
        "id": "JLagIJ7jsHOo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['remainder__payment'] # extrai a primeira coluna, que é o label para a variavel y\n",
        "X = df.drop(['remainder__payment'], axis=1) #deleta a coluna payment e copia o df para a variavel x\n",
        "\n",
        "df = X.values\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(df)\n",
        "X = pd.DataFrame(x_scaled)"
      ],
      "metadata": {
        "id": "chI1AFfmsL7t"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "count1=0\n",
        "count2=0\n",
        "for i in range(10): #Loop para executar a divisão dos dados de testes/treino e execução\n",
        "  train_data, test_data, train_labels, test_labels = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=None)\n",
        "\n",
        "  model1 = DecisionTreeRegressor()\n",
        "  model2 = DecisionTreeRegressor(criterion=\"poisson\", max_depth=2, min_samples_split=20)\n",
        "  model1.fit(train_data, train_labels)\n",
        "  model2.fit(train_data, train_labels)\n",
        "\n",
        "  result1 = model1.predict(test_data)\n",
        "  result2 = model2.predict(test_data)\n",
        "  print(mean_squared_error(test_labels, result1))\n",
        "  print(mean_squared_error(test_labels, result2))"
      ],
      "metadata": {
        "id": "n66a-YggsQs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "count1=0\n",
        "count2=0\n",
        "for i in range(10): #Loop para executar a divisão dos dados de testes/treino e execução\n",
        "  train_data, test_data, train_labels, test_labels = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=None)\n",
        "\n",
        "  model3 = KNeighborsRegressor()\n",
        "  model4 = KNeighborsRegressor(n_neighbors=11, algorithm=\"brute\", weights=\"distance\")\n",
        "\n",
        "  model3.fit(train_data, train_labels)\n",
        "  model4.fit(train_data, train_labels)\n",
        "\n",
        "  result3 = model3.predict(test_data)\n",
        "  result4 = model4.predict(test_data)\n",
        "  print(mean_squared_error(test_labels, result3))\n",
        "  print(mean_squared_error(test_labels, result4))\n",
        "  # print(mean_squared_error(test_labels, result3))"
      ],
      "metadata": {
        "id": "GaVIznlwNC-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "count1=0\n",
        "count2=0\n",
        "for i in range(10): #Loop para executar a divisão dos dados de testes/treino e execução\n",
        "  train_data, test_data, train_labels, test_labels = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=None)\n",
        "\n",
        "  model5 = MLPRegressor()\n",
        "  model6 = MLPRegressor(hidden_layer_sizes=50, activation=\"identity\", solver=\"lbfgs\")\n",
        "\n",
        "  model5.fit(train_data, train_labels)\n",
        "  model6.fit(train_data, train_labels)\n",
        "\n",
        "  result5 = model5.predict(test_data)\n",
        "  result6 = model5.predict(test_data)\n",
        "  print(mean_squared_error(test_labels, result5))\n",
        "  print(mean_squared_error(test_labels, result6))"
      ],
      "metadata": {
        "id": "29dYukOOSdDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "count1=0\n",
        "count2=0\n",
        "for i in range(10): #Loop para executar a divisão dos dados de testes/treino e execução\n",
        "  train_data, test_data, train_labels, test_labels = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=None)\n",
        "\n",
        "  model7 = SVR()\n",
        "  model8 = SVR(kernel=\"linear\", C=0.5, gamma=\"auto\")\n",
        "\n",
        "  model7.fit(train_data, train_labels)\n",
        "  model8.fit(train_data, train_labels)\n",
        "\n",
        "  result7 = model7.predict(test_data)\n",
        "  result8 = model8.predict(test_data)\n",
        "  print(mean_squared_error(test_labels, result7))\n",
        "  print(mean_squared_error(test_labels, result8))"
      ],
      "metadata": {
        "id": "LWGqfbpVU7lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "\n",
        "count1=0\n",
        "count2=0\n",
        "for i in range(10): #Loop para executar a divisão dos dados de testes/treino e execução\n",
        "  train_data, test_data, train_labels, test_labels = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=None)\n",
        "\n",
        "  model9 = RandomForestRegressor(criterion=\"absolute_error\", min_samples_split=5, min_samples_leaf=3)\n",
        "  model10 = GradientBoostingRegressor(loss=\"absolute_error\", learning_rate=0.3, criterion=\"squared_error\")\n",
        "\n",
        "  model9.fit(train_data, train_labels)\n",
        "  model10.fit(train_data, train_labels)\n",
        "\n",
        "  result9 = model9.predict(test_data)\n",
        "  result10 = model10.predict(test_data)\n",
        "  print(mean_squared_error(test_labels, result9))\n",
        "  print(mean_squared_error(test_labels, result10))"
      ],
      "metadata": {
        "id": "ICfNfjofW3Q1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}